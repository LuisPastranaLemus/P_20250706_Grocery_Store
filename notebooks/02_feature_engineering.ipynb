{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7849e41b",
   "metadata": {},
   "source": [
    "#### Feature Engineering  \n",
    "\n",
    "Dataset: \n",
    "- _customers_clean.csv_\n",
    "- _inventory_clean.csv_\n",
    "- _products_clean.csv_\n",
    "- _salesforce_clean.csv_\n",
    "- _suppliers_clean.csv_\n",
    "- _transactions_clean.csv_\n",
    "\n",
    "Author: Luis Sergio Pastrana Lemus  \n",
    "Date: 2025-07-06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2428c",
   "metadata": {},
   "source": [
    "# Feature engineering â€“ Grocery store Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415af0e2",
   "metadata": {},
   "source": [
    "## __1. Libraries__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eacf5d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Define project root dynamically, gets the current directory from which the notebook belongs and moves one level upper\n",
    "project_root = Path.cwd().parent\n",
    "\n",
    "# Add src to sys.path if it is not already\n",
    "if str(project_root) not in sys.path:\n",
    "\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Import function directly (more controlled than import *)\n",
    "from src import *\n",
    "\n",
    "from functools import partial\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be37b0b",
   "metadata": {},
   "source": [
    "## __2. Path to Data file__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e7a75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build route to data file and upload\n",
    "data_file_path = project_root / \"data\" / \"processed\" / \"clean\"\n",
    "df_customers_clean = load_dataset_from_csv(data_file_path, \"customers_clean.csv\", header='infer', parse_dates=['join_date'])\n",
    "df_inventory_clean = load_dataset_from_csv(data_file_path, \"inventory_clean.csv\", header='infer', parse_dates=['date'])\n",
    "df_products_clean = load_dataset_from_csv(data_file_path, \"products_clean.csv\", header='infer')\n",
    "df_salesforce_clean = load_dataset_from_csv(data_file_path, \"salesforce_clean.csv\", header='infer')\n",
    "df_suppliers_clean = load_dataset_from_csv(data_file_path, \"suppliers_clean.csv\", header='infer')\n",
    "df_transactions_clean = load_dataset_from_csv(data_file_path, \"transactions_clean.csv\", header='infer', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db15faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format notebook output\n",
    "format_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f213604",
   "metadata": {},
   "source": [
    "## __Functions__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edc9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc07b2",
   "metadata": {},
   "source": [
    "## 3 __Casting to data types__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724341b",
   "metadata": {},
   "source": [
    "### 3.1 Casting to string data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6df0cd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call casting dtypes function from features.py and Identifying correctly missing values qith pd.NA\n",
    "\n",
    "# missing values to pd.NA\n",
    "df_inventory_clean = replace_missing_values(df_inventory_clean, include=['warehouse_location'])\n",
    "df_customers_clean = replace_missing_values(df_customers_clean, include=['segment'])\n",
    "\n",
    "# object to string\n",
    "df_products_clean = cast_datatypes(df_products_clean, 'string', c_include=['product_name', 'brand'])\n",
    "df_suppliers_clean = cast_datatypes(df_suppliers_clean, 'string', c_include=['supplier_name', 'contact_info'])\n",
    "df_customers_clean = cast_datatypes(df_customers_clean, 'string', c_include=['customer_name'])\n",
    "df_salesforce_clean = cast_datatypes(df_salesforce_clean, 'string', c_include=['employee_name'])\n",
    "\n",
    "# object to numeric\n",
    "df_products_clean = cast_datatypes(df_products_clean, 'numeric', numeric_type='Float64', c_include=['unit_cost'])\n",
    "df_customers_clean = cast_datatypes(df_customers_clean, 'numeric', numeric_type=\"Float64\", c_include=['total_spent'])\n",
    "\n",
    "# object to category\n",
    "df_products_clean = cast_datatypes(df_products_clean, 'category', c_include=['category', 'status'])\n",
    "df_inventory_clean = cast_datatypes(df_inventory_clean, 'category', c_include=['warehouse_location'])\n",
    "df_customers_clean = cast_datatypes(df_customers_clean, 'category', c_include=['segment'])\n",
    "df_salesforce_clean = cast_datatypes(df_salesforce_clean, 'category', c_include=['region'])\n",
    "\n",
    "# object to datetime\n",
    "df_inventory_clean['date'] = pd.to_datetime(df_inventory_clean['date'], errors='coerce', utc=True)\n",
    "df_customers_clean['join_date'] = pd.to_datetime(df_customers_clean['join_date'], errors='coerce', utc=True)\n",
    "df_transactions_clean['date'] = pd.to_datetime(df_transactions_clean['date'], errors='coerce', utc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c6add",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e720a",
   "metadata": {},
   "source": [
    "### 4.1 Datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511db52e",
   "metadata": {},
   "source": [
    "#### 4.1.1 DataSet_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724732b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrich Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6606df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd().parent\n",
    "processed_path = project_root / \"data\" / \"processed\" / \"feature\" / \"xxx_feature.csv\"\n",
    "\n",
    "df_xxx.to_csv(processed_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
